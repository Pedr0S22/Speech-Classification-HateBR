{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593d0666",
   "metadata": {},
   "source": [
    "# PLN Project 2 - Classic ML Models for Text Classification\n",
    "\n",
    "This notebook implements Meta 2 of the project, following a two-phase plan:\n",
    "\n",
    "**Phase 1: Best Feature Extraction Method**\n",
    "1.  **Goal:** Find the best feature representation for the HateBR dataset.\n",
    "2.  **Control Model:** `LogisticRegression` (as the fixed baseline).\n",
    "3.  **Methods Tested (x4):** `CountVectorizer`, `TfidfVectorizer`, `Word2Vec` (Average), `Doc2Vec`.\n",
    "4.  **Preprocessing (x2):** Test all methods with and without lemmatization.\n",
    "5.  **Robustness:** Run each of the 8 combinations `N_RUNS` times and average the results (F1, Precision, Recall).\n",
    "\n",
    "**Phase 2: Model Optimization with Optuna**\n",
    "1.  **Goal:** Find the best hyperparameters for the top classic models.\n",
    "2.  **Representation:** Use the *single best* representation identified in Phase 1.\n",
    "3.  **Models Tested (x3):** `LogisticRegression`, `LinearSVC` (Linear Kernel SVM), `MultinomialNB`.\n",
    "4.  **Framework:** `Optuna` is used for hyperparameter tuning.\n",
    "\n",
    "**Phase 3: Final Evaluation**\n",
    "1.  **Goal:** Report the performance of the single best model.\n",
    "2.  **Method:** The best estimator found by Optuna is trained on the full training set and evaluated on the held-out test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecfcc64",
   "metadata": {},
   "source": [
    "## Part 0: Setup, Imports and Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- General Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- NLTK and Spacy (for preprocessing) ---\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "stopwords_pt = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "\n",
    "# --- Scikit-learn (for classic ML) ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# --- Gensim (for Word2Vec/Doc2Vec) ---\n",
    "import gensim.models\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "# --- Optuna (for HPO) ---\n",
    "import optuna\n",
    "\n",
    "# --- Setup Environment ---\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "except IOError:\n",
    "    print(\"Spacy model 'pt_core_news_sm' not found. Please run:\")\n",
    "    print(\"python -m spacy download pt_core_news_sm\")\n",
    "    nlp = None\n",
    "\n",
    "# Emoji pattern\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                            u\"\\U00002702-\\U000027B0\"\n",
    "                            u\"\\U00002702-\\U000027B0\"\n",
    "                            u\"\\U000024C2-\\U0001F251\"\n",
    "                            u\"\\U0001f926-\\U0001f937\"\n",
    "                            u\"\\U00010000-\\U0010ffff\"\n",
    "                            u\"\\u2640-\\u2642\"\n",
    "                            u\"\\u2600-\\u2B55\"\n",
    "                            u\"\\u200d\"\n",
    "                            u\"\\u23cf\"\n",
    "                            u\"\\u23e9\"\n",
    "                            u\"\\u231a\"\n",
    "                            u\"\\ufe0f\"  # dingbats\n",
    "                            u\"\\u3030\"\n",
    "                            \"]\", flags=re.UNICODE)\n",
    "\n",
    "def separate_emojis(text):\n",
    "    return emoji_pattern.sub(r' \\g<0> ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f47b1b7",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca734fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_to_tokens(text, lemmatize=False):\n",
    "    \"\"\"Processes raw text into a list of clean tokens.\"\"\"\n",
    "    if nlp is None and lemmatize:\n",
    "        raise IOError(\"Spacy 'pt_core_news_sm' model not loaded. Cannot lemmatize.\")\n",
    "\n",
    "    text = str(text).lower()\n",
    "    text = separate_emojis(text)\n",
    "\n",
    "    if lemmatize:\n",
    "        doc = nlp(text)\n",
    "        tokens = [token.lemma_ if not emoji_pattern.fullmatch(token.text) else token.text\n",
    "                for token in doc]\n",
    "    else:\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "    tokens = [t for t in tokens if t.strip() != \"\" and t not in {\"Ô∏è\", \"\\u200d\"}]\n",
    "\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        # Remove punctuation\n",
    "        if token in string.punctuation:\n",
    "            continue\n",
    "        token = re.sub(r\"\\.\\*\", \"\", token) # Remove artifacts\n",
    "        parts = re.split(f\"[{re.escape(string.punctuation)}]\", token) # Split on punctuation (e.g., \"doente.pilantra\")\n",
    "        filtered_tokens.extend([p.lower() for p in parts if p])\n",
    "\n",
    "    # Remove stopwords but keep emojis\n",
    "    final_tokens = [token for token in filtered_tokens if token not in stopwords_pt or emoji_pattern.fullmatch(token)]\n",
    "\n",
    "    return final_tokens\n",
    "\n",
    "def preprocess_to_string(text, lemmatize=False):\n",
    "    \"\"\"Processes raw text into a single string of clean tokens for vectorizers.\"\"\"\n",
    "    tokens = preprocess_to_tokens(text, lemmatize=lemmatize)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22793ebf",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6889d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'comentario', 'anotator1', 'anotator2', 'anotator3',\n",
      "       'label_final', 'links_post', 'account_post'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comentario</th>\n",
       "      <th>anotator1</th>\n",
       "      <th>anotator2</th>\n",
       "      <th>anotator3</th>\n",
       "      <th>label_final</th>\n",
       "      <th>links_post</th>\n",
       "      <th>account_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mais um lixo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Essa nao tem vergonha na cara!!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Essa mulher √© doente.pilantra!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Comunista safada...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vagabunda. Comunista. Mentirosa. O povo chileno nao merece uma desgra√ßa desta.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>6996</td>\n",
       "      <td>Parab√©ns Eduardo!!! Deus te proteja. Obrigada por tudo üôèüáßüá∑üíöüíõ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.instagram.com/p/C5rDlbTPTJq/</td>\n",
       "      <td>Eduardo Bolsonaro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>6997</td>\n",
       "      <td>A melhor maneira de unir a direita do mundo todo!!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.instagram.com/p/C5rDlbTPTJq/</td>\n",
       "      <td>Eduardo Bolsonaro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>6998</td>\n",
       "      <td>Vcs s√£o lutadores. Sejam protegidos.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.instagram.com/p/C5rDlbTPTJq/</td>\n",
       "      <td>Eduardo Bolsonaro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>6999</td>\n",
       "      <td>Parab√©ns Deus aben√ßoe üôå, que a verdade traga a justi√ßa.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.instagram.com/p/C5rDlbTPTJq/</td>\n",
       "      <td>Eduardo Bolsonaro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>7000</td>\n",
       "      <td>Agradecer a Deus por colocar esses anjos para defender o povo honesto do Brasil, estamos juntos nessa luta, povo unido.Vomos nos unir em ora√ß√£o para que Deus proteja voc√™s.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.instagram.com/p/C5rDlbTPTJq/</td>\n",
       "      <td>Eduardo Bolsonaro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0        1   \n",
       "1        2   \n",
       "2        3   \n",
       "3        4   \n",
       "4        5   \n",
       "...    ...   \n",
       "6995  6996   \n",
       "6996  6997   \n",
       "6997  6998   \n",
       "6998  6999   \n",
       "6999  7000   \n",
       "\n",
       "                                                                                                                                                                        comentario  \\\n",
       "0                                                                                                                                                                     Mais um lixo   \n",
       "1                                                                                                                                                  Essa nao tem vergonha na cara!!   \n",
       "2                                                                                                                                                   Essa mulher √© doente.pilantra!   \n",
       "3                                                                                                                                                              Comunista safada...   \n",
       "4                                                                                                   Vagabunda. Comunista. Mentirosa. O povo chileno nao merece uma desgra√ßa desta.   \n",
       "...                                                                                                                                                                            ...   \n",
       "6995                                                                                                                  Parab√©ns Eduardo!!! Deus te proteja. Obrigada por tudo üôèüáßüá∑üíöüíõ   \n",
       "6996                                                                                                                            A melhor maneira de unir a direita do mundo todo!!   \n",
       "6997                                                                                                                                          Vcs s√£o lutadores. Sejam protegidos.   \n",
       "6998                                                                                                                       Parab√©ns Deus aben√ßoe üôå, que a verdade traga a justi√ßa.   \n",
       "6999  Agradecer a Deus por colocar esses anjos para defender o povo honesto do Brasil, estamos juntos nessa luta, povo unido.Vomos nos unir em ora√ß√£o para que Deus proteja voc√™s.   \n",
       "\n",
       "      anotator1  anotator2  anotator3  label_final  \\\n",
       "0             1          1          1            1   \n",
       "1             1          1          1            1   \n",
       "2             1          1          1            1   \n",
       "3             1          1          1            1   \n",
       "4             1          1          1            1   \n",
       "...         ...        ...        ...          ...   \n",
       "6995          0          0          0            0   \n",
       "6996          0          0          0            0   \n",
       "6997          0          0          0            0   \n",
       "6998          0          0          0            0   \n",
       "6999          0          0          0            0   \n",
       "\n",
       "                                    links_post       account_post  \n",
       "0     https://www.instagram.com/p/B2uThqdH9xI/     Carla Zambelli  \n",
       "1     https://www.instagram.com/p/B2uThqdH9xI/     Carla Zambelli  \n",
       "2     https://www.instagram.com/p/B2uThqdH9xI/     Carla Zambelli  \n",
       "3     https://www.instagram.com/p/B2uThqdH9xI/     Carla Zambelli  \n",
       "4     https://www.instagram.com/p/B2uThqdH9xI/     Carla Zambelli  \n",
       "...                                        ...                ...  \n",
       "6995  https://www.instagram.com/p/C5rDlbTPTJq/  Eduardo Bolsonaro  \n",
       "6996  https://www.instagram.com/p/C5rDlbTPTJq/  Eduardo Bolsonaro  \n",
       "6997  https://www.instagram.com/p/C5rDlbTPTJq/  Eduardo Bolsonaro  \n",
       "6998  https://www.instagram.com/p/C5rDlbTPTJq/  Eduardo Bolsonaro  \n",
       "6999  https://www.instagram.com/p/C5rDlbTPTJq/  Eduardo Bolsonaro  \n",
       "\n",
       "[7000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading dataset\n",
    "url = \"https://raw.githubusercontent.com/franciellevargas/HateBR/refs/heads/main/dataset/HateBR.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "X = df['comentario']\n",
    "y = df['label_final']\n",
    "\n",
    "print(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0916d53e",
   "metadata": {},
   "source": [
    "## Part 1: Best Feature Extraction Method\n",
    "\n",
    "We will run `N_RUNS` experiments. In each run, we split the data differently and train all 8 combinations.\n",
    "This gives us a robust average score for each method.\n",
    "\n",
    "**Control Model:** `LogisticRegression(solver='liblinear')`\n",
    "\n",
    "**Combinations (2x4=8):**\n",
    "1.  `CountVectorizer` (No Lemma)\n",
    "2.  `CountVectorizer` (With Lemma)\n",
    "3.  `TfidfVectorizer` (No Lemma)\n",
    "4.  `TfidfVectorizer` (With Lemma)\n",
    "5.  `Word2Vec (Average)` (No Lemma)\n",
    "6.  `Word2Vec (Average)` (With Lemma)\n",
    "7.  `Doc2Vec` (No Lemma)\n",
    "8.  `Doc2Vec` (With Lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5966031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e860ab337f2d4ab29560eeb2c13dfde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total Runs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Run 1/5 | Lemma_False ---\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a324524358e74166b3de366418aed10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Train Data:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CountVectorizer...\n",
      "...done in 2.57s\n",
      "Testing TfidfVectorizer...\n",
      "...done in 2.42s\n",
      "Testing Word2Vec (Average)...\n",
      "...done in 0.90s\n",
      "Testing Doc2Vec...\n",
      "...done in 25.67s\n",
      "\n",
      "--- Run 1/5 | Lemma_True ---\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41f8025ee874423b97ecb4192abfe0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Train Data:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CountVectorizer...\n",
      "...done in 99.46s\n",
      "Testing TfidfVectorizer...\n",
      "...done in 97.05s\n",
      "Testing Word2Vec (Average)...\n",
      "...done in 0.84s\n",
      "Testing Doc2Vec...\n",
      "...done in 31.67s\n",
      "\n",
      "--- Run 2/5 | Lemma_False ---\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36235b060f0445e9b8f8490279d5f1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Train Data:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CountVectorizer...\n",
      "...done in 3.45s\n",
      "Testing TfidfVectorizer...\n",
      "...done in 3.33s\n",
      "Testing Word2Vec (Average)...\n",
      "...done in 1.09s\n",
      "Testing Doc2Vec...\n",
      "...done in 40.67s\n",
      "\n",
      "--- Run 2/5 | Lemma_True ---\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c24910b9af14dfb9208e1da7fa1d534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Train Data:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CountVectorizer...\n",
      "...done in 115.32s\n",
      "Testing TfidfVectorizer...\n",
      "...done in 114.63s\n",
      "Testing Word2Vec (Average)...\n",
      "...done in 1.13s\n",
      "Testing Doc2Vec...\n",
      "...done in 40.97s\n",
      "\n",
      "--- Run 3/5 | Lemma_False ---\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e939185cb1ad4665b2c8a4c547d1fa33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Train Data:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CountVectorizer...\n",
      "...done in 3.54s\n",
      "Testing TfidfVectorizer...\n",
      "...done in 3.37s\n",
      "Testing Word2Vec (Average)...\n",
      "...done in 1.10s\n",
      "Testing Doc2Vec...\n",
      "...done in 40.50s\n",
      "\n",
      "--- Run 3/5 | Lemma_True ---\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b9350869554be0ab8e326b33001174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Train Data:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CountVectorizer...\n",
      "...done in 87.55s\n",
      "Testing TfidfVectorizer...\n",
      "...done in 88.30s\n",
      "Testing Word2Vec (Average)...\n",
      "...done in 0.86s\n",
      "Testing Doc2Vec...\n",
      "...done in 25.79s\n",
      "\n",
      "--- Run 4/5 | Lemma_False ---\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e7e4ffad3a4695ac4de26311436470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Train Data:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CountVectorizer...\n",
      "...done in 2.31s\n",
      "Testing TfidfVectorizer...\n",
      "...done in 2.53s\n",
      "Testing Word2Vec (Average)...\n",
      "...done in 0.84s\n",
      "Testing Doc2Vec...\n",
      "...done in 26.03s\n",
      "\n",
      "--- Run 4/5 | Lemma_True ---\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a7ff12d27843c2a03a01d360aac6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Train Data:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CountVectorizer...\n",
      "...done in 84.48s\n",
      "Testing TfidfVectorizer...\n",
      "...done in 91.92s\n",
      "Testing Word2Vec (Average)...\n",
      "...done in 1.10s\n",
      "Testing Doc2Vec...\n",
      "...done in 41.10s\n",
      "\n",
      "--- Run 5/5 | Lemma_False ---\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032f55dc098b4715ac9f1bf150924465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Train Data:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CountVectorizer...\n",
      "...done in 2.41s\n",
      "Testing TfidfVectorizer...\n",
      "...done in 2.26s\n",
      "Testing Word2Vec (Average)...\n",
      "...done in 0.77s\n",
      "Testing Doc2Vec...\n",
      "...done in 31.49s\n",
      "\n",
      "--- Run 5/5 | Lemma_True ---\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235e416d472548b1a4f275b3a591f0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing Train Data:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing CountVectorizer...\n",
      "...done in 87.98s\n",
      "Testing TfidfVectorizer...\n",
      "...done in 89.29s\n",
      "Testing Word2Vec (Average)...\n",
      "...done in 0.89s\n",
      "Testing Doc2Vec...\n",
      "...done in 28.65s\n",
      "\n",
      "--- Phase 1 Complete ---\n"
     ]
    }
   ],
   "source": [
    "N_RUNS = 5  # Number of iterations for robust scoring\n",
    "W2V_DIM = 100 # Dimensionality for Word2Vec/Doc2Vec\n",
    "\n",
    "# Use defaultdict for easy score appending\n",
    "results = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculates F1, Precision, and Recall (weighted).\"\"\"\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    return f1, precision, recall\n",
    "\n",
    "def document_vector_avg(tokens, model, num_features):\n",
    "    \"\"\"Creates an average vector for a document from a Word2Vec model.\"\"\"\n",
    "    feature_vec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    n_words = 0\n",
    "    for word in tokens:\n",
    "        if word in model.wv:\n",
    "            n_words += 1\n",
    "            feature_vec = np.add(feature_vec, model.wv[word])\n",
    "    if n_words > 0:\n",
    "        feature_vec = np.divide(feature_vec, n_words)\n",
    "    return feature_vec\n",
    "\n",
    "for run in tqdm(range(N_RUNS), desc=\"Total Runs\"):\n",
    "    \n",
    "    # Split data differently for each run for robustness and reproducibility\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=run, stratify=y)\n",
    "    \n",
    "    # Baseline Model\n",
    "    control_model_lr = LogisticRegression(solver='liblinear', random_state=run, max_iter=1000)\n",
    "\n",
    "    # Iterate over lemmatization options\n",
    "    for lemmatize_enabled in [False, True]:\n",
    "        lem_key = \"Lemma_True\" if lemmatize_enabled else \"Lemma_False\"\n",
    "        print(f\"\\n--- Run {run+1}/{N_RUNS} | {lem_key} ---\")\n",
    "\n",
    "        # --- A. Pre-process all data for this setting ---\n",
    "        print(f\"Preprocessing text...\")\n",
    "        # For CountVect/TF-IDF (returns string)\n",
    "        # We use a wrapper that will be called by the pipeline's preprocessor\n",
    "        preprocessor_str_func = lambda text: preprocess_to_string(text, lemmatize=lemmatize_enabled)\n",
    "        \n",
    "        # For W2V/D2V (returns list of tokens)\n",
    "        X_train_tok = [preprocess_to_tokens(text, lemmatize=lemmatize_enabled) for text in tqdm(X_train, desc=\"Tokenizing Train Data\")]\n",
    "        X_test_tok = [preprocess_to_tokens(text, lemmatize=lemmatize_enabled) for text in X_test]\n",
    "        \n",
    "        # --- B. Test Sparse Vectors: CountVectorizer & TF-IDF ---\n",
    "        for vect_name, vectorizer in [('CountVectorizer', CountVectorizer(preprocessor=preprocessor_str_func)),\n",
    "                                    ('TfidfVectorizer', TfidfVectorizer(preprocessor=preprocessor_str_func))]:\n",
    "            print(f\"Testing {vect_name}...\")\n",
    "            try:\n",
    "                # Create and train the pipeline\n",
    "                pipeline_lr = Pipeline([\n",
    "                    ('vect', vectorizer),\n",
    "                    ('clf', control_model_lr)\n",
    "                ])\n",
    "                start_time = time.time()\n",
    "                pipeline_lr.fit(X_train, y_train) # Pass raw X_train, preprocessor is in the vectorizer\n",
    "                y_pred = pipeline_lr.predict(X_test)\n",
    "                print(f\"...done in {time.time() - start_time:.2f}s\")\n",
    "                \n",
    "                # Store scores\n",
    "                f1, p, r = get_metrics(y_test, y_pred)\n",
    "                results[vect_name][lem_key]['f1'].append(f1)\n",
    "                results[vect_name][lem_key]['precision'].append(p)\n",
    "                results[vect_name][lem_key]['recall'].append(r)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed {vect_name} with LR: {e}\")\n",
    "\n",
    "        # --- C. Test Dense Vectors: Word2Vec (Average) ---\n",
    "        print(\"Testing Word2Vec (Average)...\")\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            # 1. Train W2V model on training tokens\n",
    "            w2v_model = gensim.models.Word2Vec(X_train_tok, vector_size=W2V_DIM, window=5, min_count=2, workers=4, epochs=10)\n",
    "            \n",
    "            # 2. Transform tokens to vectors\n",
    "            X_train_w2v = np.array([document_vector_avg(tokens, w2v_model, W2V_DIM) for tokens in X_train_tok])\n",
    "            X_test_w2v = np.array([document_vector_avg(tokens, w2v_model, W2V_DIM) for tokens in X_test_tok])\n",
    "            \n",
    "            # 3. Train and eval Logistic Regression\n",
    "            control_model_lr.fit(X_train_w2v, y_train)\n",
    "            y_pred_lr = control_model_lr.predict(X_test_w2v)\n",
    "            print(f\"...done in {time.time() - start_time:.2f}s\")\n",
    "            \n",
    "            f1, p, r = get_metrics(y_test, y_pred_lr)\n",
    "            results['Word2Vec'][lem_key]['f1'].append(f1)\n",
    "            results['Word2Vec'][lem_key]['precision'].append(p)\n",
    "            results['Word2Vec'][lem_key]['recall'].append(r)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed Word2Vec: {e}\")\n",
    "\n",
    "        # --- D. Test Dense Vectors: Doc2Vec ---\n",
    "        print(\"Testing Doc2Vec...\")\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            # 1. Tag documents\n",
    "            tagged_train_data = [TaggedDocument(words=tokens, tags=[i]) for i, tokens in enumerate(X_train_tok)]\n",
    "            \n",
    "            # 2. Train D2V model\n",
    "            d2v_model = gensim.models.Doc2Vec(vector_size=W2V_DIM, window=5, min_count=2, workers=4, epochs=40, dm=1)\n",
    "            d2v_model.build_vocab(tagged_train_data)\n",
    "            d2v_model.train(tagged_train_data, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)\n",
    "            \n",
    "            # 3. Infer vectors\n",
    "            X_train_d2v = np.array([d2v_model.infer_vector(tokens) for tokens in X_train_tok])\n",
    "            X_test_d2v = np.array([d2v_model.infer_vector(tokens) for tokens in X_test_tok])\n",
    "            \n",
    "            # 4. Train and eval Logistic Regression\n",
    "            control_model_lr.fit(X_train_d2v, y_train)\n",
    "            y_pred_lr = control_model_lr.predict(X_test_d2v)\n",
    "            print(f\"...done in {time.time() - start_time:.2f}s\")\n",
    "            \n",
    "            f1, p, r = get_metrics(y_test, y_pred_lr)\n",
    "            results['Doc2Vec'][lem_key]['f1'].append(f1)\n",
    "            results['Doc2Vec'][lem_key]['precision'].append(p)\n",
    "            results['Doc2Vec'][lem_key]['recall'].append(r)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed Doc2Vec: {e}\")\n",
    "\n",
    "print(\"\\n--- Phase 1 Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cea00d",
   "metadata": {},
   "source": [
    "### Phase 1 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd227733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature Extraction Phase 1 Results (Ranked by Mean F1) ---\n",
      "| Vectorizer      | Lemmatization   |   Mean F1 |   Std F1 |   Mean Precision |   Mean Recall |\n",
      "|:----------------|:----------------|----------:|---------:|-----------------:|--------------:|\n",
      "| CountVectorizer | Lemma_True      |    0.8415 |   0.0117 |           0.8447 |        0.8419 |\n",
      "| TfidfVectorizer | Lemma_True      |    0.8344 |   0.0111 |           0.8347 |        0.8344 |\n",
      "| CountVectorizer | Lemma_False     |    0.8340 |   0.0106 |           0.8382 |        0.8344 |\n",
      "| TfidfVectorizer | Lemma_False     |    0.8288 |   0.0059 |           0.8293 |        0.8289 |\n",
      "| Doc2Vec         | Lemma_True      |    0.7689 |   0.0067 |           0.7696 |        0.7690 |\n",
      "| Doc2Vec         | Lemma_False     |    0.7594 |   0.0058 |           0.7597 |        0.7594 |\n",
      "| Word2Vec        | Lemma_True      |    0.7309 |   0.0100 |           0.7417 |        0.7333 |\n",
      "| Word2Vec        | Lemma_False     |    0.7293 |   0.0107 |           0.7444 |        0.7326 |\n",
      "\n",
      "--- Best Combination ---_\n",
      "\n",
      "Vectorizer        CountVectorizer\n",
      "Lemmatization          Lemma_True\n",
      "Mean F1                  0.841522\n",
      "Std F1                   0.011703\n",
      "Mean Precision           0.844723\n",
      "Mean Recall              0.841857\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "summary_results = []\n",
    "\n",
    "for vect_name, lem_dict in results.items():\n",
    "    for lem_key, metrics_dict in lem_dict.items():\n",
    "        # We use F1 as the primary comparison metric\n",
    "        f1_scores = metrics_dict.get('f1', [])\n",
    "        if not f1_scores:\n",
    "            # Fallback if key is 'f1_lr' etc.\n",
    "            f1_scores = metrics_dict.get('f1_lr', [])\n",
    "        \n",
    "        if f1_scores:\n",
    "            mean_f1 = np.mean(f1_scores)\n",
    "            std_f1 = np.std(f1_scores)\n",
    "            mean_p = np.mean(metrics_dict.get('precision', metrics_dict.get('precision_lr', [])))\n",
    "            mean_r = np.mean(metrics_dict.get('recall', metrics_dict.get('recall_lr', [])))\n",
    "            \n",
    "            summary_results.append({\n",
    "                'Vectorizer': vect_name,\n",
    "                'Lemmatization': lem_key,\n",
    "                'Mean F1': mean_f1,\n",
    "                'Std F1': std_f1,\n",
    "                'Mean Precision': mean_p,\n",
    "                'Mean Recall': mean_r\n",
    "            })\n",
    "\n",
    "# Create a DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(summary_results)\n",
    "results_df = results_df.sort_values(by='Mean F1', ascending=False)\n",
    "\n",
    "print(\"--- Feature Extraction Phase 1 Results (Ranked by Mean F1) ---\")\n",
    "print(results_df.to_markdown(index=False, floatfmt=\".4f\"))\n",
    "\n",
    "# Get the winning combination\n",
    "best_combination = results_df.iloc[0]\n",
    "print(\"\\n--- Best Combination ---_\\n\")\n",
    "print(best_combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a4f53",
   "metadata": {},
   "source": [
    "## Part 2: Model Optimization (Optuna)\n",
    "\n",
    "Now, we take the winning combination from Part 1 and use it as the fixed representation for tuning our three classifiers: `LogisticRegression`, `LinearSVC`, and `MultinomialNB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625969ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Phase 2 with ---\n",
      "Vectorizer: CountVectorizer\n",
      "Lemmatization: True\n",
      "Vector Type: sparse\n",
      "\n",
      "Preparing full dataset for optimization...\n",
      "Preprocessing full training set for Optuna...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e0d0b8c45d462abc5df91090f97c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing Optuna Train:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete.\n",
      "\n",
      "Data preparation complete.\n"
     ]
    }
   ],
   "source": [
    "# --- !!! SET THESE VARIABLES BASED ON PHASE 1 RESULTS !!! ---\n",
    "# The code automatically picks the winner from the DataFrame above.\n",
    "# You can also override them manually, e.g.:\n",
    "# best_vect_name = 'TfidfVectorizer'\n",
    "# BEST_LEMMATIZATION = False\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# We get the winner from the 'results_df' DataFrame\n",
    "best_vect_name = best_combination['Vectorizer']\n",
    "BEST_LEMMATIZATION = best_combination['Lemmatization'] == 'Lemma_True'\n",
    "\n",
    "if best_vect_name == 'CountVectorizer':\n",
    "    BEST_VECTORIZER_CLASS = CountVectorizer\n",
    "    BEST_VECTORIZER_TYPE = 'sparse'\n",
    "elif best_vect_name == 'TfidfVectorizer':\n",
    "    BEST_VECTORIZER_CLASS = TfidfVectorizer\n",
    "    BEST_VECTORIZER_TYPE = 'sparse'\n",
    "elif best_vect_name == 'Word2Vec':\n",
    "    BEST_VECTORIZER_CLASS = 'w2v' # Special case flag\n",
    "    BEST_VECTORIZER_TYPE = 'dense'\n",
    "else: # Doc2Vec\n",
    "    BEST_VECTORIZER_CLASS = 'd2v' # Special case flag\n",
    "    BEST_VECTORIZER_TYPE = 'dense'\n",
    "\n",
    "\n",
    "print(f\"--- Starting Phase 2 with ---\")\n",
    "print(f\"Vectorizer: {best_vect_name}\")\n",
    "print(f\"Lemmatization: {BEST_LEMMATIZATION}\")\n",
    "print(f\"Vector Type: {BEST_VECTORIZER_TYPE}\")\n",
    "\n",
    "# Prepare the final, full training and test sets for Optuna\n",
    "print(\"\\nPreparing full dataset for optimization...\")\n",
    "X_train_full, X_test_final, y_train_full, y_test_final = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# These variables will be used by the Optuna objectives\n",
    "X_opt_train = None\n",
    "y_opt_train = y_train_full\n",
    "\n",
    "# Create the preprocessor function based on the winner\n",
    "preprocessor_func = lambda text: preprocess_to_string(text, lemmatize=BEST_LEMMATIZATION)\n",
    "\n",
    "if BEST_VECTORIZER_TYPE == 'sparse':\n",
    "    # For sparse models, we pass the PRE-PROCESSED text\n",
    "    print(\"Preprocessing full training set for Optuna...\")\n",
    "    X_opt_train = [preprocessor_func(text) for text in tqdm(X_train_full, desc=\"Preprocessing Optuna Train\")]\n",
    "    print(\"Preprocessing complete.\")\n",
    "\n",
    "print(\"\\nData preparation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a88e26",
   "metadata": {},
   "source": [
    "### Optuna Objective Functions\n",
    "\n",
    "**Note:** If `BEST_VECTORIZER_TYPE` is 'dense', `MultinomialNB` cannot be used and will be replaced by `GaussianNB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4ad93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "N_OPTUNA_TRIALS = 50 # Number of trials for each model\n",
    "CV_FOLDS = 10 # Number of cross-validation folds\n",
    "\n",
    "# --- Define the metrics we want to track ---\n",
    "scoring_metrics = {\n",
    "    'f1': 'f1_weighted',\n",
    "    'precision': 'precision_weighted',\n",
    "    'recall': 'recall_weighted'\n",
    "}\n",
    "\n",
    "# --- Objective 1: Logistic Regression ---\n",
    "def objective_lr(trial):\n",
    "    \n",
    "    if BEST_VECTORIZER_TYPE == 'sparse':\n",
    "        vect_params = {\n",
    "            'ngram_range': trial.suggest_categorical('vect__ngram_range', [(1, 1), (1, 2)]),\n",
    "            'min_df': trial.suggest_int('vect__min_df', 1, 5),\n",
    "            'max_df': trial.suggest_float('vect__max_df', 0.5, 1.0)\n",
    "        }\n",
    "        solver = trial.suggest_categorical('clf__solver', ['liblinear', 'saga'])\n",
    "        penalty = trial.suggest_categorical('clf__penalty', ['l1', 'l2'])\n",
    "        \n",
    "        if solver == 'liblinear' and penalty == 'l1':\n",
    "            clf_params = {'solver': solver, 'penalty': penalty}\n",
    "        elif solver == 'saga' and penalty == 'l1':\n",
    "            clf_params = {'solver': solver, 'penalty': penalty}\n",
    "        else:\n",
    "            clf_params = {'solver': solver, 'penalty': 'l2'}\n",
    "            \n",
    "        clf_params['C'] = trial.suggest_float('clf__C', 1e-2, 1e2, log=True)\n",
    "            \n",
    "        pipeline = Pipeline([\n",
    "            ('vect', BEST_VECTORIZER_CLASS(preprocessor=None, **vect_params)),\n",
    "            ('clf', LogisticRegression(random_state=42, max_iter=2000, class_weight='balanced', **clf_params))\n",
    "        ])\n",
    "        X_data = X_opt_train\n",
    "    \n",
    "    # Use cross_validate to get all scores\n",
    "    scores = cross_validate(pipeline, X_data, y_opt_train, n_jobs=-1, cv=CV_FOLDS, scoring=scoring_metrics)\n",
    "    \n",
    "    # Calculate means\n",
    "    mean_f1 = np.mean(scores['test_f1'])\n",
    "    mean_precision = np.mean(scores['test_precision'])\n",
    "    mean_recall = np.mean(scores['test_recall'])\n",
    "    \n",
    "    # Store the other metrics as user attributes\n",
    "    trial.set_user_attr(\"mean_precision\", mean_precision)\n",
    "    trial.set_user_attr(\"mean_recall\", mean_recall)\n",
    "    \n",
    "    # Return the primary metric for optimization\n",
    "    return mean_f1\n",
    "\n",
    "# --- Objective 2: Linear SVM (LinearSVC) ---\n",
    "def objective_svc(trial):\n",
    "    \n",
    "    if BEST_VECTORIZER_TYPE == 'sparse':\n",
    "        vect_params = {\n",
    "            'ngram_range': trial.suggest_categorical('vect__ngram_range', [(1, 1), (1, 2)]),\n",
    "            'min_df': trial.suggest_int('vect__min_df', 1, 5),\n",
    "            'max_df': trial.suggest_float('vect__max_df', 0.5, 1.0)\n",
    "        }\n",
    "        clf_params = {\n",
    "            'C': trial.suggest_float('clf__C', 1e-3, 1e3, log=True),\n",
    "        }\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('vect', BEST_VECTORIZER_CLASS(preprocessor=None, **vect_params)),\n",
    "            ('clf', LinearSVC(random_state=42, max_iter=3000, class_weight='balanced', dual='auto', **clf_params))\n",
    "        ])\n",
    "        X_data = X_opt_train\n",
    "    \n",
    "    scores = cross_validate(pipeline, X_data, y_opt_train, n_jobs=-1, cv=CV_FOLDS, scoring=scoring_metrics)\n",
    "    mean_f1 = np.mean(scores['test_f1'])\n",
    "    mean_precision = np.mean(scores['test_precision'])\n",
    "    mean_recall = np.mean(scores['test_recall'])\n",
    "    trial.set_user_attr(\"mean_precision\", mean_precision)\n",
    "    trial.set_user_attr(\"mean_recall\", mean_recall)\n",
    "    return mean_f1\n",
    "\n",
    "# --- Objective 3: Naive Bayes ---\n",
    "def objective_nb(trial):\n",
    "    \n",
    "    if BEST_VECTORIZER_TYPE == 'sparse':\n",
    "        vect_params = {\n",
    "            'ngram_range': trial.suggest_categorical('vect__ngram_range', [(1, 1), (1, 2)]),\n",
    "            'min_df': trial.suggest_int('vect__min_df', 1, 5),\n",
    "            'max_df': trial.suggest_float('vect__max_df', 0.5, 1.0)\n",
    "        }\n",
    "        clf_params = {\n",
    "            'alpha': trial.suggest_float('clf__alpha', 1e-2, 1.0, log=True),\n",
    "        }\n",
    "        pipeline = Pipeline([\n",
    "            ('vect', BEST_VECTORIZER_CLASS(preprocessor=None, **vect_params)),\n",
    "            ('clf', MultinomialNB(**clf_params))\n",
    "        ])\n",
    "        X_data = X_opt_train\n",
    "    \n",
    "    scores = cross_validate(pipeline, X_data, y_opt_train, n_jobs=-1, cv=CV_FOLDS, scoring=scoring_metrics)\n",
    "    mean_f1 = np.mean(scores['test_f1'])\n",
    "    mean_precision = np.mean(scores['test_precision'])\n",
    "    mean_recall = np.mean(scores['test_recall'])\n",
    "    trial.set_user_attr(\"mean_precision\", mean_precision)\n",
    "    trial.set_user_attr(\"mean_recall\", mean_recall)\n",
    "    return mean_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b15fd3",
   "metadata": {},
   "source": [
    "### Run Optuna Studies\n",
    "\n",
    "This will run `N_OPTUNA_TRIALS` for each of the 3 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3b04d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Optuna: Logistic Regression ---\n",
      "Best F1 (LR): 0.8452\n",
      "Best Precision (LR): 0.8488\n",
      "Best Recall (LR): 0.8455\n",
      "Best Params (LR): {'vect__ngram_range': (1, 1), 'vect__min_df': 1, 'vect__max_df': 0.7980908810289892, 'clf__solver': 'saga', 'clf__penalty': 'l2', 'clf__C': 10.663142276044136}\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Starting Optuna: Logistic Regression ---\")\n",
    "study_lr = optuna.create_study(direction=\"maximize\", study_name=\"LogisticRegression\")\n",
    "study_lr.optimize(objective_lr, n_trials=N_OPTUNA_TRIALS)\n",
    "\n",
    "# Get metrics from the best trial\n",
    "best_f1_lr = study_lr.best_value\n",
    "best_precision_lr = study_lr.best_trial.user_attrs.get('mean_precision', 0.0)\n",
    "best_recall_lr = study_lr.best_trial.user_attrs.get('mean_recall', 0.0)\n",
    "\n",
    "print(f\"Best F1 (LR): {best_f1_lr:.4f}\")\n",
    "print(f\"Best Precision (LR): {best_precision_lr:.4f}\")\n",
    "print(f\"Best Recall (LR): {best_recall_lr:.4f}\")\n",
    "print(f\"Best Params (LR): {study_lr.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5ff9039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Optuna: Linear SVM (LinearSVC) ---\n",
      "Best F1 (SVC): 0.8447\n",
      "Best Precision (SVC): 0.8494\n",
      "Best Recall (SVC): 0.8452\n",
      "Best Params (SVC): {'vect__ngram_range': (1, 1), 'vect__min_df': 1, 'vect__max_df': 0.8858961492775645, 'clf__C': 0.3240578544555904}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Starting Optuna: Linear SVM (LinearSVC) ---\")\n",
    "study_svc = optuna.create_study(direction=\"maximize\", study_name=\"LinearSVC\")\n",
    "study_svc.optimize(objective_svc, n_trials=N_OPTUNA_TRIALS)\n",
    "\n",
    "# Get metrics from the best trial\n",
    "best_f1_svc = study_svc.best_value\n",
    "best_precision_svc = study_svc.best_trial.user_attrs.get('mean_precision', 0.0)\n",
    "best_recall_svc = study_svc.best_trial.user_attrs.get('mean_recall', 0.0)\n",
    "\n",
    "print(f\"Best F1 (SVC): {best_f1_svc:.4f}\")\n",
    "print(f\"Best Precision (SVC): {best_precision_svc:.4f}\")\n",
    "print(f\"Best Recall (SVC): {best_recall_svc:.4f}\")\n",
    "print(f\"Best Params (SVC): {study_svc.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2086fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Optuna: Naive Bayes ---\n",
      "Best F1 (NB): 0.8391\n",
      "Best Precision (NB): 0.8423\n",
      "Best Recall (NB): 0.8395\n",
      "Best Params (NB): {'vect__ngram_range': (1, 1), 'vect__min_df': 1, 'vect__max_df': 0.9861175047992199, 'clf__alpha': 0.45685531324161627}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Starting Optuna: Naive Bayes ---\")\n",
    "study_nb = optuna.create_study(direction=\"maximize\", study_name=\"NaiveBayes\")\n",
    "study_nb.optimize(objective_nb, n_trials=N_OPTUNA_TRIALS)\n",
    "\n",
    "# Get metrics from the best trial\n",
    "best_f1_nb = study_nb.best_value\n",
    "best_precision_nb = study_nb.best_trial.user_attrs.get('mean_precision', 0.0)\n",
    "best_recall_nb = study_nb.best_trial.user_attrs.get('mean_recall', 0.0)\n",
    "\n",
    "print(f\"Best F1 (NB): {best_f1_nb:.4f}\")\n",
    "print(f\"Best Precision (NB): {best_precision_nb:.4f}\")\n",
    "print(f\"Best Recall (NB): {best_recall_nb:.4f}\")\n",
    "print(f\"Best Params (NB): {study_nb.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a2fc9",
   "metadata": {},
   "source": [
    "## Part 3: Final Evaluation\n",
    "\n",
    "We now find the overall best model from the three Optuna studies and run it on the final hold-out test set (`X_test_final`, `y_test_final`) to get our reportable score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "591b6e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Overall Winner: LogisticRegression ---\n",
      "Best cross-val F1: 0.8452\n",
      "Best cross-val Precision: 0.8488\n",
      "Best cross-val Recall: 0.8455\n",
      "Best Hyperparameters: {'vect__ngram_range': (1, 1), 'vect__min_df': 1, 'vect__max_df': 0.7980908810289892, 'clf__solver': 'saga', 'clf__penalty': 'l2', 'clf__C': 10.663142276044136}\n",
      "\n",
      "Building final model with best parameters...\n",
      "Training final pipeline on full training data...\n",
      "Preprocessing final test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e16611c03f84e63a148af670ae33349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing Test Set:   0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on final test set...\n",
      "\n",
      "--- FINAL CLASSIFICATION REPORT ---\n",
      "Model: LogisticRegression\n",
      "Vectorizer: CountVectorizer\n",
      "Lemmatization: True\n",
      "\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Not Offensive (0)       0.83      0.88      0.86       700\n",
      "    Offensive (1)       0.87      0.82      0.85       700\n",
      "\n",
      "         accuracy                           0.85      1400\n",
      "        macro avg       0.85      0.85      0.85      1400\n",
      "     weighted avg       0.85      0.85      0.85      1400\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "studies = {\n",
    "    'LogisticRegression': study_lr,\n",
    "    'LinearSVC': study_svc,\n",
    "    'NaiveBayes': study_nb\n",
    "}\n",
    "\n",
    "# Find the best model among the three studies\n",
    "best_model_name = \"\"\n",
    "best_study = None\n",
    "best_score = -1\n",
    "\n",
    "for name, study in studies.items():\n",
    "    if study.best_value > best_score:\n",
    "        best_score = study.best_value\n",
    "        best_model_name = name\n",
    "        best_study = study\n",
    "\n",
    "print(f\"--- Overall Winner: {best_model_name} ---\")\n",
    "print(f\"Best cross-val F1: {best_score:.4f}\")\n",
    "\n",
    "# Print all metrics for the winner\n",
    "best_precision = best_study.best_trial.user_attrs.get('mean_precision', 0.0)\n",
    "best_recall = best_study.best_trial.user_attrs.get('mean_recall', 0.0)\n",
    "print(f\"Best cross-val Precision: {best_precision:.4f}\")\n",
    "print(f\"Best cross-val Recall: {best_recall:.4f}\")\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_study.best_params}\")\n",
    "\n",
    "# Re-build the final, best pipeline with the best params\n",
    "print(\"\\nBuilding final model with best parameters...\")\n",
    "final_pipeline = None\n",
    "best_params = best_study.best_params\n",
    "\n",
    "if BEST_VECTORIZER_TYPE == 'sparse':\n",
    "    # Separate vectorizer and classifier params from Optuna's keys\n",
    "    vect_params = {k.replace('vect__', ''): v for k, v in best_params.items() if k.startswith('vect__')}\n",
    "    clf_params = {k.replace('clf__', ''): v for k, v in best_params.items() if k.startswith('clf__')}\n",
    "    \n",
    "    # Set preprocessor to None (it's already done)\n",
    "    vect_params['preprocessor'] = None\n",
    "    \n",
    "    vectorizer = BEST_VECTORIZER_CLASS(**vect_params)\n",
    "    \n",
    "    classifier = None\n",
    "    \n",
    "    if best_model_name == 'LogisticRegression':\n",
    "        classifier = LogisticRegression(random_state=42, max_iter=2000, class_weight='balanced', **clf_params)\n",
    "    elif best_model_name == 'LinearSVC':\n",
    "        classifier = LinearSVC(random_state=42, max_iter=3000, class_weight='balanced', dual='auto', **clf_params)\n",
    "    elif best_model_name == 'NaiveBayes':\n",
    "        classifier = MultinomialNB(**clf_params)\n",
    "        \n",
    "    final_pipeline = Pipeline([\n",
    "        ('vect', vectorizer),\n",
    "        ('clf', classifier)\n",
    "    ])\n",
    "    \n",
    "    # Train on the full training data\n",
    "    print(\"Training final pipeline on full training data...\")\n",
    "    final_pipeline.fit(X_opt_train, y_opt_train)\n",
    "    \n",
    "    # Preprocess the final test set\n",
    "    print(\"Preprocessing final test set...\")\n",
    "    X_test_final_processed = [preprocessor_func(text) for text in tqdm(X_test_final, desc=\"Preprocessing Test Set\")]\n",
    "    \n",
    "    # Predict on the hold-out test set\n",
    "    print(\"Evaluating on final test set...\")\n",
    "    final_predictions = final_pipeline.predict(X_test_final_processed)\n",
    "\n",
    "# Final Report\n",
    "print(\"\\n--- FINAL CLASSIFICATION REPORT ---\")\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Vectorizer: {best_vect_name}\")\n",
    "print(f\"Lemmatization: {BEST_LEMMATIZATION}\")\n",
    "print(\"\\n\")\n",
    "target_names = ['Not Offensive (0)', 'Offensive (1)']\n",
    "print(classification_report(y_test_final, final_predictions, target_names=target_names))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "cm = confusion_matrix(y_test_final, final_predictions)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=target_names,\n",
    "            yticklabels=target_names)\n",
    "\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(f\"Final Confusion Matrix: {best_model_name}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
